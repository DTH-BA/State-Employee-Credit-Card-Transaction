{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c742983-3fd5-4b15-9010-2ccb8a91ecb9",
   "metadata": {},
   "source": [
    "# State Employee Credit Card Transactions — Phase 3: Data Cleaning\n",
    "\n",
    "**Project Summary:** This project analyzes state employee credit card transactions to identify spending patterns, high-value or unusual transactions, and potential data quality issues.  \n",
    "**This Notebook (Phase 3) Purpose:** Clean and standardize the raw dataset to produce an analysis-ready table for dashboards and further modeling.\n",
    "\n",
    "**Objectives of Phase 3**\n",
    "- Normalize text fields (departments, divisions, merchants, categories).\n",
    "- Parse and validate dates and numeric types.\n",
    "- Create transaction flags (e.g., refunds, high-value, potential duplicates).\n",
    "- Export a clean table for Tableau.\n",
    "\n",
    "**Deliverables**\n",
    "- `clean_state_cc_phase3.csv` (analysis-ready)\n",
    "- A short data dictionary for new/changed columns\n",
    "- Inline “before → after” checks for each cleaning step (transparency and auditability)\n",
    "\n",
    "**Scope & Assumptions**\n",
    "- Only transactional fields included in the raw file are cleaned here.\n",
    "- No external enrichment (merchant master, GL codes) in this phase.\n",
    "- Duplicates are flagged (not hard-deleted) to preserve auditability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625d0fd9-6feb-493d-b79d-941344abe9a3",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preview\n",
    "\n",
    "The dataset **State Employee Credit Card Transactions** was loaded into a pandas DataFrame from a CSV file.  \n",
    "Warnings were suppressed for cleaner output. The first five rows were displayed to verify successful loading and review the structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70789fe8-9fe4-4a01-902e-dda0c868178e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FISCAL_YEAR</th>\n",
       "      <th>FISCAL_PERIOD</th>\n",
       "      <th>DEPT_NAME</th>\n",
       "      <th>DIV_NAME</th>\n",
       "      <th>MERCHANT</th>\n",
       "      <th>CAT_DESCR</th>\n",
       "      <th>TRANS_DT</th>\n",
       "      <th>MERCHANDISE_AMT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025</td>\n",
       "      <td>12</td>\n",
       "      <td>FREIRE CHARTER SCHOOL</td>\n",
       "      <td>Freire Charter School</td>\n",
       "      <td>AMAZON MKTPL*N64SF7SY0</td>\n",
       "      <td>Book Stores</td>\n",
       "      <td>2025-06-06</td>\n",
       "      <td>299.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025</td>\n",
       "      <td>12</td>\n",
       "      <td>FREIRE CHARTER SCHOOL</td>\n",
       "      <td>Freire Charter School</td>\n",
       "      <td>CITY OF WILMINGTON</td>\n",
       "      <td>Utlts-Elctrc Gas Heating Oil Sanitary Water</td>\n",
       "      <td>2025-06-13</td>\n",
       "      <td>792.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025</td>\n",
       "      <td>12</td>\n",
       "      <td>FREIRE CHARTER SCHOOL</td>\n",
       "      <td>Freire Charter School</td>\n",
       "      <td>BJS WHOLESALE #0354</td>\n",
       "      <td>Wholesale Clubs</td>\n",
       "      <td>2025-05-27</td>\n",
       "      <td>55.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025</td>\n",
       "      <td>12</td>\n",
       "      <td>FREIRE CHARTER SCHOOL</td>\n",
       "      <td>Freire Charter School</td>\n",
       "      <td>CHICK-FIL-A #05288</td>\n",
       "      <td>Fast Food Restaurants</td>\n",
       "      <td>2025-06-04</td>\n",
       "      <td>549.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025</td>\n",
       "      <td>12</td>\n",
       "      <td>FREIRE CHARTER SCHOOL</td>\n",
       "      <td>Freire Charter School</td>\n",
       "      <td>DISCOUNTMUGS.COM</td>\n",
       "      <td>Miscellaneous General Merchandise</td>\n",
       "      <td>2025-05-30</td>\n",
       "      <td>3392.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FISCAL_YEAR  FISCAL_PERIOD              DEPT_NAME               DIV_NAME  \\\n",
       "0         2025             12  FREIRE CHARTER SCHOOL  Freire Charter School   \n",
       "1         2025             12  FREIRE CHARTER SCHOOL  Freire Charter School   \n",
       "2         2025             12  FREIRE CHARTER SCHOOL  Freire Charter School   \n",
       "3         2025             12  FREIRE CHARTER SCHOOL  Freire Charter School   \n",
       "4         2025             12  FREIRE CHARTER SCHOOL  Freire Charter School   \n",
       "\n",
       "                 MERCHANT                                    CAT_DESCR  \\\n",
       "0  AMAZON MKTPL*N64SF7SY0                                  Book Stores   \n",
       "1      CITY OF WILMINGTON  Utlts-Elctrc Gas Heating Oil Sanitary Water   \n",
       "2     BJS WHOLESALE #0354                              Wholesale Clubs   \n",
       "3      CHICK-FIL-A #05288                        Fast Food Restaurants   \n",
       "4        DISCOUNTMUGS.COM            Miscellaneous General Merchandise   \n",
       "\n",
       "    TRANS_DT  MERCHANDISE_AMT  \n",
       "0 2025-06-06           299.70  \n",
       "1 2025-06-13           792.48  \n",
       "2 2025-05-27            55.94  \n",
       "3 2025-06-04           549.00  \n",
       "4 2025-05-30          3392.60  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset and inspect the first 5 rows\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Read dataset\n",
    "df = pd.read_csv(\"C:/Users/theha/OneDrive/Desktop/Projects/2. State Employee Credit Card Transaction/Data_raw/State_Employee_Credit_Card_Transactions_20250804.csv\", parse_dates=[\"TRANS_DT\"], na_values=[\"\", \" \", \"N/A\", \"NULL\"])\n",
    "\n",
    "# Screening of data structure\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d620b139-f2ca-4dfa-a465-ea41154f4c64",
   "metadata": {},
   "source": [
    "## 1.1) Dataset structure & missing value check\n",
    "\n",
    "Before starting the cleaning process, we inspect the dataset to understand:\n",
    "- **Shape** — number of rows and columns.\n",
    "- **Data types** — ensure numerical/date fields are correctly parsed.\n",
    "- **Missing values** — identify if any fields require imputation or removal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33f817d8-ed3c-42ff-a4ee-8d11bbfbaf51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(742191, 8)\n",
      "FISCAL_YEAR                 int64\n",
      "FISCAL_PERIOD               int64\n",
      "DEPT_NAME                  object\n",
      "DIV_NAME                   object\n",
      "MERCHANT                   object\n",
      "CAT_DESCR                  object\n",
      "TRANS_DT           datetime64[ns]\n",
      "MERCHANDISE_AMT           float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e128236-ab9d-4c1f-9aa5-fc476ae2c17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FISCAL_YEAR        0\n",
      "FISCAL_PERIOD      0\n",
      "DEPT_NAME          0\n",
      "DIV_NAME           0\n",
      "MERCHANT           0\n",
      "CAT_DESCR          0\n",
      "TRANS_DT           0\n",
      "MERCHANDISE_AMT    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6537ae27-e795-43b1-aca1-b45166a085af",
   "metadata": {},
   "source": [
    "**Observations from this dataset:**\n",
    "- Shape: **742,191 rows × 8 columns**.\n",
    "- `FISCAL_YEAR`, `FISCAL_PERIOD` are integers.\n",
    "- `DEPT_NAME`, `DIV_NAME`, `MERCHANT`, `CAT_DESCR` are text (object) — will need normalization.\n",
    "- `TRANS_DT` is already in `datetime64[ns]` format.\n",
    "- `MERCHANDISE_AMT` is `float64` — correct for monetary values.\n",
    "- No missing values in any column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c353aa-39c5-4005-a5e1-b576207a1e6b",
   "metadata": {},
   "source": [
    "## 1.2) Duplicate check using a composite key\n",
    "\n",
    "Duplicate transactions can occur when:\n",
    "- The same purchase is recorded twice (e.g., system glitches).\n",
    "- Multiple systems feed the same transaction into the dataset.\n",
    "- Two legitimate transactions happen to have identical details (e.g., split bills, recurring charges).\n",
    "\n",
    "**Method:**  \n",
    "We define a **composite key** — a set of columns that together should uniquely identify a transaction:\n",
    "- `DEPT_NAME`, `MERCHANT`, `CAT_DESCR`, `TRANS_DT`, `MERCHANDISE_AMT`.\n",
    "\n",
    "Using `DataFrame.duplicated(subset=key_cols)`, we count rows where all these fields match another row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b66682b9-7708-4557-b9a7-d226c4c0893b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate rows: 50685\n"
     ]
    }
   ],
   "source": [
    "# Duplicate check using composite key\n",
    "key_cols = [\"DEPT_NAME\", \"MERCHANT\", \"CAT_DESCR\", \"TRANS_DT\", \"MERCHANDISE_AMT\"]\n",
    "print(\"Duplicate rows:\", df.duplicated(subset=key_cols).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4a5711-8bd6-423d-9496-7203343b10a6",
   "metadata": {},
   "source": [
    "**Results:**  \n",
    "- Found **50,685** duplicate rows based on the composite key.\n",
    "- These are not removed immediately — instead, we will flag them in later steps for transparency and auditability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76d4851-cd06-4ef3-a4a0-c4c9fcb9221f",
   "metadata": {},
   "source": [
    "### 1.3 Merchandise Amount Analysis\n",
    "\n",
    "The `MERCHANDISE_AMT` column was analyzed to understand the distribution of transaction amounts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d19988ec-b7ee-4238-8378-bf21d145c9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    742191.000000\n",
      "mean        449.331251\n",
      "std        2551.582215\n",
      "min     -368335.100000\n",
      "25%          23.990000\n",
      "50%          75.920000\n",
      "75%         281.250000\n",
      "max      379505.580000\n",
      "Name: MERCHANDISE_AMT, dtype: float64\n",
      "Negative amounts: 15364\n"
     ]
    }
   ],
   "source": [
    "# Amount column stats\n",
    "print(df[\"MERCHANDISE_AMT\"].describe())\n",
    "print(\"Negative amounts:\", (df[\"MERCHANDISE_AMT\"] < 0).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214570e1-0699-4b01-8c48-5b8ff6c14e25",
   "metadata": {},
   "source": [
    "**Notable Findings:**\n",
    "- 15,364 transactions have negative amounts, likely indicating refunds or adjustments.\n",
    "- The large range between minimum and maximum values suggests the presence of outliers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e69eec-55d9-42d3-856a-1b4a90fb2b5c",
   "metadata": {},
   "source": [
    "### 1.4 Transaction Date Range\n",
    "\n",
    "The `TRANS_DT` column was examined to determine the time span of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25de748a-ea8b-4144-99b4-dcec0a9b935b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min date: 2021-06-09 00:00:00\n",
      "Max date: 2025-06-27 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Date column stats\n",
    "print(\"Min date:\", df[\"TRANS_DT\"].min())\n",
    "print(\"Max date:\", df[\"TRANS_DT\"].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20abc160-9500-4fb7-ac56-84e2d0d1cbab",
   "metadata": {},
   "source": [
    "**Findings:**\n",
    "- Earliest transaction date: 2021-06-09\n",
    "- Latest transaction date: 2025-06-27\n",
    "\n",
    "This indicates the dataset covers approximately four years of transaction history."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7953b44-044d-4397-8351-f0e84e78831c",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning and Preparation\n",
    "\n",
    "Moving forward from the initial dataset overview, the next step focuses on **data cleaning** to ensure consistency and accuracy in subsequent analysis.\n",
    "\n",
    "### 2.1 Text Normalization\n",
    "Standardize categorical text fields to remove inconsistencies caused by spacing and capitalization issues.\n",
    "\n",
    "**Columns processed:**\n",
    "- `DEPT_NAME`\n",
    "- `DIV_NAME`\n",
    "- `MERCHANT`\n",
    "- `CAT_DESCR`\n",
    "\n",
    "**Cleaning steps:**\n",
    "1. Trim and collapse multiple spaces into one.\n",
    "2. Preserve original casing for `MERCHANT` (vendor IDs).\n",
    "3. Apply title case to other categorical fields.\n",
    "4. Compare unique value counts before and after cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2aa1f192-16c1-40e8-88bd-fa92ea3364ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPT_NAME unique before cleaning: 67\n",
      "DEPT_NAME\n",
      "Dept Of Natrl Res And Env Cont    93140\n",
      "Dept Of Corrections               76753\n",
      "Dept Of Transportation            66748\n",
      "Appoquinimink School District     47813\n",
      "Dept Of Health And Social Sv      47413\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "DIV_NAME unique before cleaning: 304\n",
      "DIV_NAME\n",
      "Appoquinimink School District    47813\n",
      "Maintenance Districts            43687\n",
      "Parks And Recreation             43016\n",
      "Fish And Wildlife                22119\n",
      "Facilities Maintenance           18392\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "MERCHANT unique before cleaning: 183141\n",
      "MERCHANT\n",
      "GRAINGER                       15651\n",
      "VERIZONWRLSS*RTCCR VB          11901\n",
      "EASTERN SHORE COFFEE And WA     8024\n",
      "UBER TRIP                       5265\n",
      "WALMART.COM                     4881\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n",
      "CAT_DESCR unique before cleaning: 252\n",
      "CAT_DESCR\n",
      "Book Stores                                        91872\n",
      "Eating Places Restaurants                          42879\n",
      "Stationery-Office Supplies-Printing Writing Pap    35167\n",
      "Industrial Supplies Not Elsewhere Classified       31836\n",
      "Lodging                                            30276\n",
      "Name: count, dtype: int64\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Step 3.1 – Text cleaning\n",
    "\n",
    "cat_cols = [\"DEPT_NAME\", \"DIV_NAME\", \"MERCHANT\", \"CAT_DESCR\"]\n",
    "\n",
    "def normalize_text(s):\n",
    "    if pd.isna(s): \n",
    "        return s\n",
    "    return \" \".join(str(s).strip().split())\n",
    "\n",
    "# keep original case for MERCHANT; title-case others\n",
    "for c in cat_cols:\n",
    "    df[c] = df[c].map(normalize_text)\n",
    "\n",
    "for c in [\"DEPT_NAME\",\"DIV_NAME\",\"CAT_DESCR\"]:\n",
    "    df[c] = df[c].str.title()\n",
    "    \n",
    "# Check changes\n",
    "for c in cat_cols:\n",
    "    print(f\"{c} unique before cleaning:\", df[c].nunique())\n",
    "    print(df[c].value_counts().head(5))\n",
    "    print(\"-\"*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d99fbe-b36b-43de-b2f6-da377703065a",
   "metadata": {},
   "source": [
    "**Results:**\n",
    "- Reduced inconsistencies in department, division, and category descriptions.\n",
    "- Preserved vendor formatting in `MERCHANT` to retain unique IDs.\n",
    "- Example: `\"Dept of Corrections\"` and `\"DEPT OF CORRECTIONS\"` are now standardized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad00e3c6-74e5-4c08-9dec-be32f040ad62",
   "metadata": {},
   "source": [
    "### 2.2 Amount Flags and Thresholds\n",
    "Create additional features for the `MERCHANDISE_AMT` column to support outlier detection and financial anomaly analysis.\n",
    "\n",
    "**Steps:**\n",
    "1. `IS_REFUND` – flag transactions with negative amounts.\n",
    "2. `AMOUNT_ABS` – store absolute transaction value for consistent analysis.\n",
    "3. `IS_HIGH_VALUE` – flag transactions exceeding the 99.5th percentile within each department."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d93acf2-f400-49c7-834f-ab522b761d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refund count: 15364\n",
      "High-value count: 3773\n",
      "       MERCHANDISE_AMT      IS_REFUND  IS_HIGH_VALUE\n",
      "count    742191.000000  742191.000000  742191.000000\n",
      "mean        449.331251       0.020701       0.005084\n",
      "std        2551.582215       0.142381       0.071118\n",
      "min     -368335.100000       0.000000       0.000000\n",
      "25%          23.990000       0.000000       0.000000\n",
      "50%          75.920000       0.000000       0.000000\n",
      "75%         281.250000       0.000000       0.000000\n",
      "max      379505.580000       1.000000       1.000000\n"
     ]
    }
   ],
   "source": [
    "amt_col = \"MERCHANDISE_AMT\"\n",
    "\n",
    "# Refund flag\n",
    "df[\"IS_REFUND\"] = (df[amt_col] < 0).astype(\"int8\")\n",
    "\n",
    "# Absolute amount\n",
    "df[\"AMOUNT_ABS\"] = df[amt_col].abs()\n",
    "\n",
    "# High-value threshold per department\n",
    "thr = df.groupby(\"DEPT_NAME\")[amt_col].transform(lambda x: x.quantile(0.995))\n",
    "df[\"IS_HIGH_VALUE\"] = (df[\"AMOUNT_ABS\"] > thr).astype(\"int8\")\n",
    "\n",
    "# Quick check\n",
    "print(\"Refund count:\", df[\"IS_REFUND\"].sum())\n",
    "print(\"High-value count:\", df[\"IS_HIGH_VALUE\"].sum())\n",
    "print(df[[amt_col,\"IS_REFUND\",\"IS_HIGH_VALUE\"]].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621ca9b3-7927-42a1-9096-7bc2bd78050a",
   "metadata": {},
   "source": [
    "**Results:**\n",
    "- Refund transactions: **15,364**\n",
    "- High-value transactions: **3,773**\n",
    "\n",
    "**Insights:**\n",
    "- Refund flag helps isolate reversed or corrected charges.\n",
    "- High-value flag supports identification of potential anomalies for further investigation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3bc7f2-3806-4f16-b1dd-6573b071c4dc",
   "metadata": {},
   "source": [
    "### 2.3 Duplicate Transaction Check\n",
    "\n",
    "Identify and review potential duplicate transactions to ensure data integrity.\n",
    "\n",
    "**Steps:**\n",
    "1. Define key columns for duplicate detection:  \n",
    "   `FISCAL_YEAR`, `FISCAL_PERIOD`, `DEPT_NAME`, `DIV_NAME`, `MERCHANT`, `CAT_DESCR`, `TRANS_DT`, `MERCHANDISE_AMT`\n",
    "2. Use `duplicated()` to find repeated rows based on these keys.\n",
    "3. Group duplicates for inspection by counting occurrences.\n",
    "4. Display samples of duplicate groups for manual verification.\n",
    "\n",
    "Purpose:  \n",
    "- Detect possible repeated transactions that could distort analysis.\n",
    "- Support decision-making on whether to keep or remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0172a6a2-1edd-4cc3-bfbe-dbc02318dc52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows flagged as exact duplicates: 76675\n",
      "Distinct duplicate groups: 25990\n",
      "\n",
      "Sample duplicate key combos (top 10 by group size):\n",
      "                             DEPT_NAME                  MERCHANT  \\\n",
      "4558         Del Tech And Comm College   DLTCRP BACKGROUND CHECK   \n",
      "327672       Del Tech And Comm College   DLTCRP BACKGROUND CHECK   \n",
      "182990       Del Tech And Comm College   DLTCRP BACKGROUND CHECK   \n",
      "297928       Del Tech And Comm College             COL PRKNG WTC   \n",
      "378470   Caesar Rodney School District    HOLIDAY INN EXP DENVER   \n",
      "195302   New Castle County Vo-Tech Sch   DLTCRP BACKGROUND CHECK   \n",
      "518332       Del Tech And Comm College   DLTCRP BACKGROUND CHECK   \n",
      "581612       Del Tech And Comm College   DLTCRP BACKGROUND CHECK   \n",
      "403860  Sussex Technical Schl District   DLTCRP BACKGROUND CHECK   \n",
      "356518                       Executive  CITY OF WILM-DIV REVENUE   \n",
      "\n",
      "                                           CAT_DESCR   TRANS_DT  \\\n",
      "4558    Government Services-Not Elsewhere Classified 2025-06-16   \n",
      "327672  Government Services-Not Elsewhere Classified 2023-09-28   \n",
      "182990  Government Services-Not Elsewhere Classified 2024-07-16   \n",
      "297928           Automobile Parking Lots And Garages 2023-12-04   \n",
      "378470                                       Lodging 2023-07-12   \n",
      "195302  Government Services-Not Elsewhere Classified 2024-06-20   \n",
      "518332  Government Services-Not Elsewhere Classified 2022-10-12   \n",
      "581612  Government Services-Not Elsewhere Classified 2022-06-09   \n",
      "403860  Government Services-Not Elsewhere Classified 2023-05-18   \n",
      "356518  Government Services-Not Elsewhere Classified 2023-09-20   \n",
      "\n",
      "        MERCHANDISE_AMT  KEY_GROUP_SIZE  \n",
      "4558              25.00              55  \n",
      "327672            25.00              45  \n",
      "182990            25.00              40  \n",
      "297928             4.00              40  \n",
      "378470            83.63              40  \n",
      "195302            25.00              38  \n",
      "518332            25.00              37  \n",
      "581612            25.00              35  \n",
      "403860            25.00              35  \n",
      "356518            50.00              35  \n",
      "\n",
      "Preview rows from first duplicate group:\n",
      "      FISCAL_YEAR  FISCAL_PERIOD                  DEPT_NAME      DIV_NAME  \\\n",
      "4413         2025             12  Del Tech And Comm College  Owens Campus   \n",
      "4419         2025             12  Del Tech And Comm College  Owens Campus   \n",
      "4422         2025             12  Del Tech And Comm College  Owens Campus   \n",
      "4423         2025             12  Del Tech And Comm College  Owens Campus   \n",
      "4424         2025             12  Del Tech And Comm College  Owens Campus   \n",
      "\n",
      "                     MERCHANT                                     CAT_DESCR  \\\n",
      "4413  DLTCRP BACKGROUND CHECK  Government Services-Not Elsewhere Classified   \n",
      "4419  DLTCRP BACKGROUND CHECK  Government Services-Not Elsewhere Classified   \n",
      "4422  DLTCRP BACKGROUND CHECK  Government Services-Not Elsewhere Classified   \n",
      "4423  DLTCRP BACKGROUND CHECK  Government Services-Not Elsewhere Classified   \n",
      "4424  DLTCRP BACKGROUND CHECK  Government Services-Not Elsewhere Classified   \n",
      "\n",
      "       TRANS_DT  MERCHANDISE_AMT  IS_REFUND  AMOUNT_ABS  IS_HIGH_VALUE  \\\n",
      "4413 2025-06-16             25.0          0        25.0              0   \n",
      "4419 2025-06-16             25.0          0        25.0              0   \n",
      "4422 2025-06-16             25.0          0        25.0              0   \n",
      "4423 2025-06-16             25.0          0        25.0              0   \n",
      "4424 2025-06-16             25.0          0        25.0              0   \n",
      "\n",
      "      KEY_GROUP_SIZE  IS_EXACT_DUP  \n",
      "4413              55             1  \n",
      "4419              55             1  \n",
      "4422              55             1  \n",
      "4423              55             1  \n",
      "4424              55             1  \n"
     ]
    }
   ],
   "source": [
    "# Step 3.4 – Exact-duplicate flag (keep rows)\n",
    "\n",
    "key_cols = [\"DEPT_NAME\",\"MERCHANT\",\"CAT_DESCR\",\"TRANS_DT\",\"MERCHANDISE_AMT\"]\n",
    "\n",
    "# 1) Size of each key-group\n",
    "grp_size = df.groupby(key_cols, dropna=False).size().rename(\"KEY_GROUP_SIZE\")\n",
    "df = df.merge(grp_size.reset_index(), on=key_cols, how=\"left\")\n",
    "\n",
    "# 2) Flag duplicates (any group with size > 1)\n",
    "df[\"IS_EXACT_DUP\"] = (df[\"KEY_GROUP_SIZE\"] > 1).astype(\"int8\")\n",
    "\n",
    "# 3) Quick stats\n",
    "dup_rows = int(df[\"IS_EXACT_DUP\"].sum())\n",
    "dup_groups = int(df.loc[df[\"IS_EXACT_DUP\"].eq(1), key_cols].drop_duplicates().shape[0])\n",
    "print(f\"Rows flagged as exact duplicates: {dup_rows}\")\n",
    "print(f\"Distinct duplicate groups: {dup_groups}\")\n",
    "\n",
    "# 4) Inspect a few duplicate groups (top by size)\n",
    "ex = (\n",
    "    df[df[\"IS_EXACT_DUP\"]==1]\n",
    "    .sort_values(\"KEY_GROUP_SIZE\", ascending=False)\n",
    "    .loc[:, key_cols + [\"KEY_GROUP_SIZE\"]]\n",
    "    .drop_duplicates()\n",
    "    .head(10)\n",
    ")\n",
    "print(\"\\nSample duplicate key combos (top 10 by group size):\")\n",
    "print(ex)\n",
    "\n",
    "# (Optional) Keep a stable example table to eyeball the actual rows\n",
    "sample_keys = ex.head(3)[key_cols]  # first 3 groups\n",
    "print(\"\\nPreview rows from first duplicate group:\")\n",
    "mask = (df[key_cols] == sample_keys.iloc[0]).all(axis=1)\n",
    "print(df.loc[mask].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5ab5d1-3a6f-4be3-9c4f-8a170b55ff37",
   "metadata": {},
   "source": [
    "**Results:**\n",
    "- Duplicate transactions were found, with some groups repeating multiple times.\n",
    "- Example: certain merchants like *Government Services via Payphone* appear multiple times with identical amounts and dates.\n",
    "- Further investigation is required to determine if these are true duplicates or legitimate repeated purchases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d26cbe-b385-4d37-98fe-c7cbb4ce2139",
   "metadata": {},
   "source": [
    "### 2.4 Deriving Calendar Features\n",
    "\n",
    "Extract additional date-related fields from `TRANS_DT` to enable time-based analysis.\n",
    "\n",
    "**Steps:**\n",
    "1. `TX_DATE` – transaction date (no time component).\n",
    "2. `TX_YEAR` – transaction year.\n",
    "3. `TX_MONTH` – transaction month (numeric).\n",
    "4. `DAY_OF_WEEK` – day name (e.g., Monday, Tuesday).\n",
    "5. `IS_WEEKEND` – flag indicating weekend transactions (Saturday or Sunday).\n",
    "\n",
    "Purpose:  \n",
    "- Enhance temporal analysis by allowing grouping and filtering by year, month, weekday, or weekend activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "876a0d88-13aa-469e-a9ad-ba2451b0e6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derive calendar parts\n",
    "df[\"TX_DATE\"] = df[\"TRANS_DT\"].dt.date\n",
    "df[\"TX_YEAR\"] = df[\"TRANS_DT\"].dt.year\n",
    "df[\"TX_MONTH\"] = df[\"TRANS_DT\"].dt.month\n",
    "df[\"DAY_OF_WEEK\"] = df[\"TRANS_DT\"].dt.day_name()\n",
    "df[\"IS_WEEKEND\"] = df[\"DAY_OF_WEEK\"].isin([\"Saturday\",\"Sunday\"]).astype(\"int8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9032433-8736-4e3e-9343-804caecdc761",
   "metadata": {},
   "source": [
    "**Results:**\n",
    "- Calendar-based features successfully added, enabling richer trend and pattern analysis.\n",
    "- Weekend transactions are now easily identifiable for behavior comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf1ee6c-cc0b-4367-9d87-6ba45475527d",
   "metadata": {},
   "source": [
    "### 2.5 Handling Missing Values\n",
    "\n",
    "Address potential missing data in categorical and date fields to ensure completeness.\n",
    "\n",
    "**Steps:**\n",
    "1. For `DEPT_NAME`, `DIV_NAME`, `MERCHANT`, and `CAT_DESCR`:\n",
    "   - Create a flag column `IS_UNKNOWN_<col>` if any values are missing.\n",
    "   - Fill missing values with `\"Unknown\"`.\n",
    "\n",
    "2. For `TRANS_DT`:\n",
    "   - Drop rows where the transaction date is missing.\n",
    "   - Log the number of rows removed.\n",
    "\n",
    "Purpose:  \n",
    "- Prevent issues during grouping or analysis caused by null values.\n",
    "- Maintain transparency by flagging missing records instead of silently removing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7891e34-81ce-49db-a700-d4fee1c9ed96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows dropped due to missing TRANS_DT: 0\n"
     ]
    }
   ],
   "source": [
    "# If any new blanks appear later, fill + flag\n",
    "for c in [\"DEPT_NAME\",\"DIV_NAME\",\"MERCHANT\",\"CAT_DESCR\"]:\n",
    "    miss = df[c].isna().sum()\n",
    "    df[f\"IS_UNKNOWN_{c}\"] = df[c].isna().astype(\"int8\")\n",
    "    if miss:\n",
    "        df[c] = df[c].fillna(\"Unknown\")\n",
    "\n",
    "# Dates: if any nulls ever occur, we’ll drop & log them\n",
    "rows_before = len(df)\n",
    "df = df[ df[\"TRANS_DT\"].notna() ].copy()\n",
    "rows_dropped_dates = rows_before - len(df)\n",
    "print(\"Rows dropped due to missing TRANS_DT:\", rows_dropped_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bb252e-bfce-4cd6-b3ae-3d861ad66863",
   "metadata": {},
   "source": [
    "**Results:**\n",
    "- No missing `TRANS_DT` values were found; no rows dropped.\n",
    "- Any future blanks in key categorical fields will be flagged and filled with `\"Unknown\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac4b893-48d1-4a35-9f83-ee483e9f865b",
   "metadata": {},
   "source": [
    "### 2.6 Data Type Optimization\n",
    "\n",
    "Convert columns to more memory-efficient data types to improve processing performance.\n",
    "\n",
    "**Steps:**\n",
    "1. **Categorical conversion** –  \n",
    "   Convert text-based fields to the `category` type:  \n",
    "   - `DEPT_NAME`, `DIV_NAME`, `MERCHANT`, `CAT_DESCR`, `DAY_OF_WEEK`\n",
    "\n",
    "2. **Integer conversion for flags** –  \n",
    "   Convert binary flag fields to `int8` for minimal memory usage:  \n",
    "   - `IS_REFUND`, `IS_HIGH_VALUE`, `IS_EXACT_DUP`, `IS_WEEKEND`  \n",
    "   - `IS_UNKNOWN_*` flag columns\n",
    "\n",
    "3. **Fiscal fields as category (optional)** –  \n",
    "   Convert `FISCAL_YEAR` and `FISCAL_PERIOD` to `category`.\n",
    "\n",
    "Purpose:  \n",
    "- Reduce memory footprint of the dataset.\n",
    "- Improve performance for grouping, filtering, and joins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4ac22b6-c809-4be4-8913-a3f7f19624ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categoricals\n",
    "for c in [\"DEPT_NAME\",\"DIV_NAME\",\"MERCHANT\",\"CAT_DESCR\",\"DAY_OF_WEEK\"]:\n",
    "    df[c] = df[c].astype(\"category\")\n",
    "\n",
    "# Small ints for flags\n",
    "for c in [\"IS_REFUND\",\"IS_HIGH_VALUE\",\"IS_EXACT_DUP\",\"IS_WEEKEND\",\n",
    "          \"IS_UNKNOWN_DEPT_NAME\",\"IS_UNKNOWN_DIV_NAME\",\"IS_UNKNOWN_MERCHANT\",\"IS_UNKNOWN_CAT_DESCR\"]:\n",
    "    if c in df.columns:\n",
    "        df[c] = df[c].astype(\"int8\")\n",
    "\n",
    "# Fiscal fields as category (optional)\n",
    "df[\"FISCAL_YEAR\"] = df[\"FISCAL_YEAR\"].astype(\"category\")\n",
    "df[\"FISCAL_PERIOD\"] = df[\"FISCAL_PERIOD\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7930af36-3fea-4407-a918-510cb4339af9",
   "metadata": {},
   "source": [
    "**Results:**\n",
    "- Key text fields converted to categories, significantly reducing memory usage.\n",
    "- All flag columns stored as compact `int8` type.\n",
    "- Fiscal fields now treated as categories for cleaner grouping and summarization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776bd6c4-af19-4757-8142-ad31e3887d2d",
   "metadata": {},
   "source": [
    "### 2.7 Data Validation Checks\n",
    "\n",
    "Perform validation tests to ensure data consistency and correctness after cleaning.\n",
    "\n",
    "**Checks performed:**\n",
    "1. **Type validation**\n",
    "   - `TRANS_DT` is a datetime field.\n",
    "   - `MERCHANDISE_AMT` is numeric.\n",
    "\n",
    "2. **Date sanity**\n",
    "   - Minimum date is on or after `2020-01-01`.\n",
    "   - Maximum date does not exceed tomorrow’s date.\n",
    "\n",
    "3. **Refund logic consistency**\n",
    "   - All transactions flagged as `IS_REFUND = 1` have negative amounts.\n",
    "\n",
    "4. **Duplicate flag presence**\n",
    "   - `IS_EXACT_DUP` column exists to track flagged duplicates.\n",
    "\n",
    "Purpose:  \n",
    "- Verify that data transformations preserved integrity.\n",
    "- Catch potential anomalies before moving to analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6331f965-971d-4ed9-a566-7f587cf03b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Types\n",
    "assert pd.api.types.is_datetime64_any_dtype(df[\"TRANS_DT\"])\n",
    "assert pd.api.types.is_numeric_dtype(df[\"MERCHANDISE_AMT\"])\n",
    "\n",
    "# Date sanity\n",
    "assert df[\"TRANS_DT\"].min() >= pd.Timestamp(\"2020-01-01\")\n",
    "assert df[\"TRANS_DT\"].max() <= pd.Timestamp.today() + pd.Timedelta(days=1)\n",
    "\n",
    "# Refund logic consistent\n",
    "assert (df.loc[df[\"IS_REFUND\"]==1, \"MERCHANDISE_AMT\"] < 0).all()\n",
    "\n",
    "# Duplicates: we flagged, so duplicates may remain; ensure flag present\n",
    "assert \"IS_EXACT_DUP\" in df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8817056f-1c0f-4dae-88e8-51f927bc731c",
   "metadata": {},
   "source": [
    "**Results:**\n",
    "- All validation checks passed successfully.\n",
    "- Dataset is ready for exploratory analysis and visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990aaefb-3435-4d70-9c3a-2f5d5e786f93",
   "metadata": {},
   "source": [
    "### 2.8 Exporting Clean Dataset\n",
    "\n",
    "Prepare and export the cleaned dataset for further analysis and dashboard creation.\n",
    "\n",
    "**Steps:**\n",
    "1. Define `cols_order` – list of columns required for dashboards and EDA.\n",
    "2. Keep only the columns that exist in the DataFrame.\n",
    "3. Export to:\n",
    "   - `transactions_clean_for_EDA.csv` – optimized for Tableau dashboard input.\n",
    "   - `transactions_clean.csv` – full cleaned dataset for general use.\n",
    "\n",
    "Purpose:  \n",
    "- Ensure consistent column ordering for downstream tools.\n",
    "- Provide both a tailored dataset for visualization and a complete cleaned version for other analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "375a4a6b-e387-49fe-b65c-61c85fc09047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export complete. Rows exported: 742191\n"
     ]
    }
   ],
   "source": [
    "# Columns needed for dashboards\n",
    "cols_order = [\n",
    "    \"FISCAL_YEAR\", \"FISCAL_PERIOD\",\n",
    "    \"DEPT_NAME\", \"DIV_NAME\", \"MERCHANT\", \"CAT_DESCR\",\n",
    "    \"TRANS_DT\", \"TX_DATE\", \"TX_YEAR\", \"TX_MONTH\", \"DAY_OF_WEEK\", \"IS_WEEKEND\",\n",
    "    \"MERCHANDISE_AMT\", \"AMOUNT_ABS\",\n",
    "    \"IS_REFUND\", \"IS_HIGH_VALUE\", \"IS_EXACT_DUP\"\n",
    "]\n",
    "\n",
    "# Keep only the columns that actually exist in df\n",
    "cols_order = [c for c in cols_order if c in df.columns]\n",
    "\n",
    "# Export to CSV for Tableau\n",
    "df[cols_order].to_csv(\"transactions_clean_for_EDA.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"Export complete. Rows exported:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3613ecf-7a68-4288-8ca6-2a6525c48600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export clean dataset\n",
    "df.to_csv(\"transactions_clean.csv\", index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549a5787-24e2-4827-b54c-b3081239ecf3",
   "metadata": {},
   "source": [
    "**Results:**\n",
    "- `transactions_clean_for_EDA.csv` – 742,191 rows exported for dashboard creation.\n",
    "- `transactions_clean.csv` – full cleaned dataset saved for future analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
